{
 "metadata": {
  "name": "",
  "signature": "sha256:9948a63fb157b93cb23f159b9aee7e6c1d707e5601d6fb900810d314cf72e013"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Parametric Experiments"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's create functions that would allow us to re-run the experiments by changing the parameters. We are particularly interested in looking at how the precision / recall values change."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import matplotlib as mpl\n",
      "import pandas\n",
      "import numpy as np\n",
      "from pandas.io.parsers import read_csv\n",
      "from admm.dict_learning import MiniBatchDictionaryLearning\n",
      "from pandas.stats.moments import rolling_apply\n",
      "from sklearn.metrics import precision_recall_curve\n",
      "from sklearn.metrics import average_precision_score\n",
      "\n",
      "%matplotlib inline\n",
      "\n",
      "def train(d, dico=None, components=200, alpha=1, n_iter=100, method='lars', batch_size=100, fit=True):\n",
      "    \n",
      "    if dico is None:\n",
      "        dico = MiniBatchDictionaryLearning(n_components=components, fit_algorithm=method, transform_algorithm='lasso_'+method, alpha=alpha, n_iter=n_iter, batch_size=batch_size)\n",
      "\n",
      "    if fit:\n",
      "        dico.fit(d)\n",
      "\n",
      "    dictionary = dico.components_\n",
      "        \n",
      "    code = dico.transform(d)\n",
      "    patches = np.dot(code, dictionary)\n",
      "    error = ((d - patches) ** 2).mean(axis=1)\n",
      "    \n",
      "    return dictionary, code, error, dico\n",
      "\n",
      "\n",
      "def draw_groundtruth(y, xstart, xstop, color='b'):\n",
      "    \"\"\"Plot timelines at y from xstart to xstop with given color.\"\"\"   \n",
      "    plt.hlines(y, xstart, xstop, color, lw=4)\n",
      "    plt.vlines(xstart, y+ 0.03, y-0.03, color, lw=2)\n",
      "    plt.vlines(xstop, y+0.03, y-0.03, color, lw=2)\n",
      "    \n",
      "\n",
      "def check(input_data, groundtruth, error_limit=0, STEP=8000):\n",
      "\n",
      "    frames = np.array(range(1, 62000))\n",
      "\n",
      "    frame_error = input_data[input_data.error > error_limit].get(['frameNum', 'error'])\n",
      "    # frame error sum\n",
      "    fes  = frame_error.groupby(by='frameNum').agg(np.sum)\n",
      "\n",
      "\n",
      "    for index in range(0, len(frames), STEP):\n",
      "        \n",
      "        frames_vect = np.array(range(index, index + STEP+1))\n",
      "\n",
      "        values_vect = np.zeros(frames_vect.shape)\n",
      "\n",
      "        for frame, error in fes[(fes.index > index) & (fes.index < index+STEP)].itertuples():\n",
      "            values_vect[frame - index] = error\n",
      "\n",
      "        plt.figure()\n",
      "        plt.gcf().set_figwidth(15)\n",
      "\n",
      "        YLIM = 10\n",
      "\n",
      "        plt.plot(frames_vect, values_vect, color='green', label='error sum')\n",
      "        plt.hold()\n",
      "\n",
      "        for start, end, value in groundtruth:\n",
      "            color = 'red' if value == 1 else 'black'\n",
      "            height = YLIM * 0.7 if value == 1 else YLIM * 0.3\n",
      "            draw_groundtruth(height, start, end, color=color)        \n",
      "            draw_groundtruth(YLIM - height, start, end, color=color)        \n",
      "\n",
      "        plt.title(\"Frames %s to %s\" % (index, index+STEP))\n",
      "\n",
      "        plt.xlim(index, index + STEP)\n",
      "        plt.ylim((0, YLIM))\n",
      "        \n",
      "    return fes\n",
      "\n",
      "def draw_trajectories(video_filename, data, groundtruth, output_video_filename, thickness=0):\n",
      "    '''Draws cuboids.\n",
      "    video_filename: string\n",
      "    data: DataFrame with frameNumber, error and trajectory\n",
      "    \n",
      "    output_video_file_name: string\n",
      "    \n",
      "    edge: width in pixels of cuboid outlines\n",
      "    outline: draws only cuboid outlines when 0, solid cuboids otherwise\n",
      "    \n",
      "    Author: Ariel Nunez, 2014\n",
      "            Juan Carlos Niebles, 2013\n",
      "    '''\n",
      "    \n",
      "    # Open input video.\n",
      "    input_video = cv2.VideoCapture(video_filename)\n",
      "    if not input_video.isOpened():\n",
      "        print \"Cannot open input video\", video_filename ,\"for reading.\"\n",
      "        return None\n",
      "    frame_width = np.uint32(input_video.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH))\n",
      "    frame_height = np.uint32(input_video.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT))\n",
      "    \n",
      "    # Open output video.\n",
      "    output_video = cv2.VideoWriter()\n",
      "    output_video.open(output_video_filename, cv2.cv.CV_FOURCC('F','M', 'P','4'),\n",
      "                      60, (frame_width, frame_height), 1)\n",
      "    if not output_video.isOpened():\n",
      "        output_video.release()\n",
      "        print \"Cannot open output video\", output_video_filename ,\"for writing.\"\n",
      "        return None\n",
      "    \n",
      "    # Keep track of current frame number.\n",
      "    frame_number = -1\n",
      "    \n",
      "    min_error = data.error.min()\n",
      "    max_error = data.error.max()\n",
      "    \n",
      "    # Loop through all frames, drawing cuboids at each frame.\n",
      "    while True:\n",
      "        retval, frame = input_video.read()\n",
      "        if (type(frame) == type(None)):\n",
      "            break\n",
      "        frame_number += 1\n",
      "        \n",
      "        ignore = True\n",
      "        usual = True\n",
      "        \n",
      "        for start, end, value in groundtruth:\n",
      "            if (frame_number > start) & (frame_number <= end):\n",
      "                if value == 1:\n",
      "                    usual = False\n",
      "                ignore = False\n",
      "                break\n",
      "        \n",
      "        # If this frame is not in the groundtruth, don't draw it.\n",
      "        if ignore:\n",
      "            continue\n",
      "\n",
      "        # When drawing a solid cuboid, we operate on the HSV color space.\n",
      "        gray_frame = cv2.cvtColor(frame.copy(), cv2.COLOR_BGR2GRAY)\n",
      "        output_frame = np.zeros((gray_frame.shape[0], gray_frame.shape[1], 3),\n",
      "                                    dtype=np.uint8)\n",
      "        output_frame[:, :, 2] = gray_frame\n",
      "        \n",
      "        # Add trajectories\n",
      "        filtered = data[(data.frameNum > frame_number) & (data.frameNum < frame_number + 15)]\n",
      "                \n",
      "        for index, row in filtered.iterrows():\n",
      "            trajectory = np.array(row.trajectory).reshape((15, 2))\n",
      "            x_last = None\n",
      "            y_last = None\n",
      "            \n",
      "            difference = row.frameNum - frame_number\n",
      "\n",
      "            for x, y in trajectory:\n",
      "                max_error, min_error, row.error\n",
      "                level = (row.error - min_error ) / (max_error - min_error)\n",
      "                color = np.array([  0.,   (level-0.2)*255., 255., 255.])\n",
      "                \n",
      "                if x_last is not None and level > 0.2:\n",
      "                    cv2.line(output_frame, (int(x_last), int(y_last)), (int(x), int(y)), color, thickness=2, lineType=cv2.CV_AA)                    \n",
      "                    \n",
      "                x_last = x\n",
      "                y_last = y\n",
      "        \n",
      "        # Add frame number\n",
      "        if usual:\n",
      "            text = '%s' % frame_number\n",
      "            color = (180, 0, 255)\n",
      "        else:\n",
      "            text = '%s (unusual)' % frame_number\n",
      "            color = (0, 128, 255)\n",
      "                    \n",
      "        cv2.putText(output_frame, text, (5, 25),\n",
      "                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, color)\n",
      "        \n",
      "        output_frame = cv2.cvtColor(output_frame, cv2.COLOR_HSV2BGR_FULL)\n",
      "        output_video.write(output_frame)\n",
      "        \n",
      "\n",
      "    print \"Done.\"\n",
      "    # Close video objects\n",
      "    input_video.release()\n",
      "    output_video.release()\n",
      "\n",
      "def unusual_events(trajectory_file='../../subway-exit-W10-complete.txt', method='lars', error_limit=0, peak_threshold=1, plot=True):\n",
      "    metadata_fields = ['frameNum', 'mean_x', 'mean_y', 'var_x', 'var_y', 'length', 'scale', 'x_pos', 'y_pos', 't_pos']\n",
      "    norm_trajectory_fields = ['norm_trajectory%s' % n for n in range(30)]\n",
      "    trajectory_fields = ['trajectory%s' % n for n in range(30)]\n",
      "    hog_fields = ['hog%s' % n for n in range(96)]\n",
      "    hof_fields = ['hof%s' % n for n in range(108)]\n",
      "    mbh_fields = ['mbh%s' % n for n in range(96+96)]\n",
      "\n",
      "    fields = metadata_fields + norm_trajectory_fields + trajectory_fields + hog_fields + hof_fields + mbh_fields\n",
      "\n",
      "    temp_data = read_csv(trajectory_file, delimiter='\\t', names=fields, index_col=False)\n",
      "    data = pandas.concat([\n",
      "            temp_data.get(metadata_fields),\n",
      "            pandas.Series(temp_data.get(hof_fields).values.tolist(), index=temp_data.index, name='hof'),\n",
      "            pandas.Series(temp_data.get(hog_fields).values.tolist(), index=temp_data.index, name='hog'),\n",
      "            pandas.Series(temp_data.get(mbh_fields).values.tolist(), index=temp_data.index, name='mbh'),\n",
      "            pandas.Series(temp_data.get(trajectory_fields).values.tolist(), index=temp_data.index, name='trajectory'),\n",
      "], axis=1)\n",
      "    \n",
      "    groundtruth = np.array( [\n",
      "    [550, 780, 0],\n",
      "    [2310, 2855, 0],\n",
      "    [3730, 3790, 0],\n",
      "    [4925, 5570, 0],\n",
      "    [5650, 5750, 0],\n",
      "    [9680, 9710, 0],\n",
      "    [12370, 12500, 0],\n",
      "    [14020, 14070, 0],\n",
      "    [14760, 14816, 0],\n",
      "    [15290, 15500, 1],\n",
      "    [15815, 15945, 0],\n",
      "    [17340, 17770, 1],\n",
      "    [18150, 18970, 1],\n",
      "    [18970, 19450, 1],\n",
      "    [19875, 19950, 0],\n",
      "    [20170, 20225, 0],\n",
      "    [20560, 20738, 1],\n",
      "    [21760, 21805, 0],\n",
      "    [22830, 23610, 0],\n",
      "    [24020, 24255, 1],\n",
      "    [37185, 37267, 0],\n",
      "    [37940, 38005, 0],\n",
      "    [40710, 41750, 1],\n",
      "    [47020, 47505, 0],\n",
      "    [47670, 47910, 1],\n",
      "    [49230, 49280, 0],\n",
      "    [50365, 50680, 1],\n",
      "    [50940, 51295, 1],\n",
      "    [52230, 52395, 0],\n",
      "    [52765, 53050, 1],\n",
      "    [53330, 53425, 0],\n",
      "    [54375, 54475, 1],\n",
      "    [55315, 56065, 1],\n",
      "    [57120, 57615, 0],\n",
      "    [59110, 62195, 1],\n",
      "    ])\n",
      "    \n",
      "    normal_data = None\n",
      "\n",
      "    # Create a dataset with only normal events.\n",
      "    for start, end, normal in groundtruth:\n",
      "\n",
      "        tmp_data = data[(data.frameNum >= start) & (data.frameNum <= end)]\n",
      "\n",
      "        # ignore events labeled as abnormal\n",
      "        if normal == 1:\n",
      "            break\n",
      "\n",
      "        normal_data = pandas.concat([normal_data, tmp_data])\n",
      "        \n",
      "    mbh = np.array(normal_data.mbh.values.tolist())\n",
      "    \n",
      "    mbh_reference = mbh\n",
      "    intercept = mbh_reference.mean(axis=0)\n",
      "    delta_reference =  mbh_reference - intercept\n",
      "    deviation = delta_reference.std(axis=0)\n",
      "\n",
      "    # Use the intercept and deviation from the initial values:\n",
      "    delta = mbh - intercept\n",
      "    d = delta / deviation\n",
      "    \n",
      "    dictionary, code, error, dico = train(d, alpha=1, method=method, n_iter=10, batch_size=100, components=50)\n",
      "    \n",
      "    normal_data['error'] = pandas.Series(error, index=normal_data.index, name='error')\n",
      "    \n",
      "    all_mbh = np.array(data.mbh.values.tolist())\n",
      "    # Use the intercept and deviation from the initial values:\n",
      "    delta = all_mbh - intercept\n",
      "    new_d = delta / deviation\n",
      "\n",
      "    code = dico.transform(new_d)\n",
      "    patches = np.dot(code, dictionary)\n",
      "    new_error = ((new_d - patches) ** 2).mean(axis=1)\n",
      "    \n",
      "    data['error'] = pandas.Series(new_error, index=data.index, name='error')\n",
      "    \n",
      "    frame_error = input_data[input_data.error > error_limit].get(['frameNum', 'error'])\n",
      "    # frame error sum\n",
      "    fes  = frame_error.groupby(by='frameNum').agg(np.sum)\n",
      "    \n",
      "    mad = lambda x: np.fabs(x - x.mean()).mean()\n",
      "    moving_window_frames = 10\n",
      "    smooth_error = rolling_apply(fes, moving_window_frames, mad)\n",
      "    smooth_error.plot(style='k')\n",
      "    \n",
      "    \n",
      "    error_peaks = smooth_error[smooth_error.error >= peak_threshold]\n",
      "    \n",
      "    result = pandas.DataFrame({\n",
      "                'start': pandas.Series(groundtruth[:,0]),\n",
      "                'end':  pandas.Series(groundtruth[:,1]),\n",
      "                'raw_reference': pandas.Series(groundtruth[:,2]),\n",
      "    })\n",
      "\n",
      "    detected = []\n",
      "    for start, end, value in groundtruth:\n",
      "        detected_value = len(error_peaks[(error_peaks.index > start) & (error_peaks.index < end)])\n",
      "        detected.append(detected_value)\n",
      "\n",
      "    detection = pandas.Series(detected, index=result.index)\n",
      "\n",
      "    result['raw_detection'] = detection\n",
      "    result['reference'] = [x==0 for x in result.raw_reference]\n",
      "    result['detection'] = [x==0 for x in result.raw_detection]\n",
      "    \n",
      "    if plot:\n",
      "        fes = check(data, groundtruth, error_limit=normal_data.error.quantile(0.992))\n",
      "        \n",
      "        data.error.plot(kind='line')\n",
      "        smooth_error.plot(kind='line')\n",
      "        error_peaks.plot(kind='line')\n",
      "        \n",
      "        # Plot Precision-Recall curve\n",
      "        plt.clf()\n",
      "        plt.plot(recall, precision, label='Precision-Recall curve')\n",
      "        plt.xlabel('Recall')\n",
      "        plt.ylabel('Precision')\n",
      "        plt.ylim([0.0, 1.05])\n",
      "        plt.xlim([0.0, 1.0])\n",
      "        plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision))\n",
      "        plt.legend(loc=\"upper right\")\n",
      "        plt.show()\n",
      "\n",
      "    return data, groundtruth, smooth_error, error_peaks, result, average_precision"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%time  data, groundtruth, smooth_error, error_peaks, result, average_precision = unusual_events(method='lars', peak_threshold=1, plot=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}